### 一、特点

Clickhouse是用于联机分析OLAP的列式DBMS，是一款PB级的交互式分析数据库

特性：列式存储 每一列存在一个文件里面，这样你要分析某个列只需要去对应文件里即可

但像mysql这样的行式存储，你需要去逐行扫描，获取相应的列，那我们知道mysql逐行扫描的效率是较低的

ck利用了vector引擎和code generation方式提高了CPU的利用率，提高了并行度，准实时分析

并且列存储可以带来一个很大的压缩比提高，因为同一列的数据是很类似的，通过压缩算法可以达到很高的一个压缩比，一般可以达到2-10，常见的话可以到达7-8左右

CK的吞吐也特别高，并提供了丰富的分析函数



**优劣势分析**

在业内CK的单机查询性能是很顶级的，一般mysql基本上50Mbps差不多，拿32核的机器去测，写入能到达300-700MB/S，

劣势在于低并发

实际业务上看建议写入尽量控制1-5qps，建议是数据攒到5-20w写一批（看数据大小）

读取：单机建议不超过400qps

因为读取是向量化引擎，并发读写时会很占用CPU资源，

不支持事务、频繁删除&修改、不擅长大表join千万级别（因为是share Nothing架构）



指标：

TPS行数/QPS请求数



### 二、存储原理

Mysql是B+树存储的结构

Clickhouse是类LSM的MergeTree结构



Zookeeper保存元数据，数据存储在本地，且会压缩



我们假设是每10w条写一批数据，CK后台是会不断Merge形成一个更大的数据文件

最终这个数据文件会被merge得越来越大，这样的好处是什么呢？

如果你理解磁盘的话，磁盘IO是顺序IO和随机IO的，如果你的文件很大的时候比如几个G，那你读取的时候大概率是顺序IO，顺序IO读取是很快的，单盘能达到几百MB/s,在这种情况下我们的吞吐是特别高的

CK是基于排序树的合并，我们会指定一些列作为排序键--归并排序（怎么把两个相对有序的数据集进行合并）

排序的一个好处是在于定位，例如我们基于时间为排序键，这样当我们比如去查询今天的数据时，就可以利用跳表的方式去快速定位。

所以为什么CK的吞吐这么高，因为它用文件的方式去写入，

性能这么强--顺序磁盘IO

所以如果CK的查询命中了排序键的话会很快，做跳表搜索



### 三、携程生态

这边是做了Ch pass平台，接入了大数据流程



在CH Pass上申请一个CK集群--->在很多平台都可以对接查询



### 四、应用场景

1、酒店数据智能平台 Hdata

- 离线数仓加速 离线数据T+1同步从hive同步到CK进行查询（和伏羲埋点类似） 来加速Hive查询

![image-20231209180550801](D:\Users\haoxiang_zhang\AppData\Roaming\Typora\typora-user-images\image-20231209180550801.png)



2、利用CK丰富的分析函数 去计算一些分析指标





### 五、原理&架构

**分片与副本**

CK还是可以通过分片来承载一张表的数据

那CK是怎么管理分片的呢？是在每个节点都会去建议一张分布式表（all表）

通过distribute引擎去建一张分布式表，然后所有分片的数据做一次聚合查询

分片规则：（当使用分布式表写入时，根据怎样的规则把数据分发到节点上）

分片权重、slot槽、选择函数



那CK是怎么把分片的数据聚合在一起查询的呢？

--用distribute引擎建一张分布式表，对分片聚合查询



**share nothing vs share disk**

CK偏向于本地做计算，不会去拉别的节点的数据

而Spark会有keyby这样的操作，share disk这样的会拉磁盘，还有网络传输，但是是load balance的 负载均衡的

但CK就是专注本地的数据计算，这样查的会比较快，但可能会有数据热点问题，即可能本次需要计算的数据都在某个节点上了



**建表**

CK的建表语句和Mysql类似，但多了一些键的设置，一般建表的引擎我们基本上都选择MergeTree引擎，即前面说的数据文件不断merge的过程



分区键：对数据文件进行分区

排序键：CK的数据都是基于排序来做的 所以这块排序键的设置很关键，在merge时要通过归并排序来merge

主键：一般主键默认就是排序键

索引粒度：跳表查询时的范围 index_granularity = 8192



**引擎**

Replicated 通过zookeeper管理好副本

+...

mergeTree

在CK里最重要的引擎就是mergeTree了，我们来聊聊它的一个存储结构

![image-20231209204414944](D:\Users\haoxiang_zhang\AppData\Roaming\Typora\typora-user-images\image-20231209204414944.png)

.bin文件：每个列会存为一个bin文件

primary.idx:主键索引

![image-20231211143708267](D:\Users\haoxiang_zhang\AppData\Roaming\Typora\typora-user-images\image-20231211143708267.png)





skp_idx_：二级索引

![image-20231211144108394](D:\Users\haoxiang_zhang\AppData\Roaming\Typora\typora-user-images\image-20231211144108394.png)



一级索引index文件：例如按照时间建索引，我们跳表定位

CK是稀疏索引，不同于稠密索引会每一条数据记录对应一个索引标记，CK是每8192条数据记录会做一个索引，具体存文件的offset位置

一级索引是最重要的，我们设置排序键的时候要把重要的放前面

二级索引：以前我们是一个granularity去跳的，现在每三个granularity记录一个minmax，然后去跳，即跳的过程中变快



**数据存储**

我们说CK是按列存储的嘛，那每一列其实会成一个bin文件，在每个bin文件内部其实是由很多个压缩数据块组成的，然后每个数据块有头部和压缩数据，按照64k-1M进行数据块压缩

![image-20231211144515334](D:\Users\haoxiang_zhang\AppData\Roaming\Typora\typora-user-images\image-20231211144515334.png)

通过数据库头文件可以快速跳过、定位





mrk文件：

标记：我们首先走一级索引，定位到编号（8192条数据为一块），然后通过mrk找到其在压缩文件中的偏移量

所以这个数据标记作为一级索引和数据桥梁，如果把索引比作目录（记录了每个章节的页码），那mrk标记就相当于每个章节内的书签



**梳理**

数据写入是按照排序键写入的，根据排序键生成idx文件即主键索引，idx文件是每8192条数据会生成一个编号

这个编号会对应mrk文件的编号，mrk文件会记录对应编号在压缩文件中的偏移量，这能帮助我们在bin文件内直接定位到块，而不是从头开始扫，每个块是有64k-1MB的大小，所以只要扫描这么小一块就可以定位到想要的数据

当然如果觉得上述跳跃不够快，可以添加二级索引，加快编号的搜索，例如变为三个8192条数据搜索一次，当然二级索引有很多，例如minmax、bloomfilter

 

### 六、MergeTree引擎家族&物化视图

**replicated**

CK是基于Zookeeper进行副本管理的，同时ZK的元数据是交给Zookeeper管理的，因此在建表时需要指定Znode的路径



**SummingMergeTree**

数据片段在进行merge的时候还可以做一些别的事情

默认会根据order by进行



**物化视图**

sunmmingMergeTree通常和物化视图在一起合作，在数据写入的时候会跑一个sql语句，帮你做一个预聚合，合并到mv表里

 关于物化视图的使用：

1. 规定必须以_mv结尾
2. 物化视图必须用local表，并且需要挂一张分布式表
3. 用户查询物化视图全量数据需要查分布式表

demo：

![image-20231211150618809](D:\Users\haoxiang_zhang\AppData\Roaming\Typora\typora-user-images\image-20231211150618809.png)



**AggregateMergeTree**

有状态的



**ReplacingMerge**

在合并分区时删除冲去数据，只是单机同分区去重



### 七、知识补充

#### 7.1.1 LSM树

LSM树是一种用于存储和管理大规模数据的数据结构，它被设计用来提供高性能的写入和查询操作

核心思想是将写入操作和查询操作分离，通过将写入操作追加到一个顺序写的日志文件，而不是直接写入到磁盘上的数据文件，从而大大提高写入操作的性能（因为顺序IO比随机IO是要更快的）

当写入的日志文件达到一定数量时，LSM树会将日志文件合并成一个更大的数据文件，来减少数据文件数量，提高查询操作性能

#### 7.1.2 CK里的类LSM树

CK采用了LSM树的设计思想，在每个分区内部使用LSM树的合并策略进行数据的合并和压缩，来减少磁盘上的数据文件数量



#### 7.2  Shared nothing VS Shared disk

两者都是分布式系统内的系统架构

shared nothing架构：每个节点都是独立的，没有共享的资源，节点负责自己的数据存储和计算任务，彼此之间不分享数据或状态

shared disk架构：所有节点共享一个中央存储设备，每个节点通过网络连接到共享存储设备，可以同时访问数据

那CK是shared nothing的架构







### 八、CK在CDP的应用

CDP呢是客户数据平台，圈人呢即根据一定的条件把合适的UID圈出来，形成一个人群

进行一些统计分析、营销、转换的全链路



条件组合---圈选人群

数据维度：

- 画像标签 UID
- 订单行为 Order
- 搜索行为 UBT

可以看到维度不同，合并成单表的代价较大

多表Join效率较低，复杂条件计算时间为小时级

无法进行准实时的数据更新



### 九、调优实践

**建表**

本地表：用于写/存数据

分布式表：用于查询，且表名带_all后缀，物化视图也需要分布式表（因为其实物化视图也是merge tree引擎）



引擎方面：

分布式表：Distributed

本地表用ReplicatedMergeTree引擎即可



表结构&属性：

分区键：分区不能太多，单次写入一个分区，单次查询涉及较少分区

优先使用大宽表，减少join

如用户uid字段去重可用bitmap存储优化

空值不适用null，用如-1的值替换



**数据写入和删除**

写入频率尽量控制1-5qps



mysql怎么查询？

为什么不能 where 字段 in (子查询)



