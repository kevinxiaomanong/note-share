### 第一部分 环境准备

**云平台**

云的本质是远程计算机，通过网络远程提供服务

而计算从广义上说可以理解为构建业务的各种需求

云平台呢是将远程硬件/软件资源组合在一起形成平台，对用户提供各种服务

平台方聚合软硬件资源对客户提供服务，如服务器、网络、数据库等各类服务

主流有：AWS亚马逊云、Azure微软、GCP谷歌云、阿里云



云平台提供的服务主要分三类

- IaaS 基础设施服务 公网IP、带宽，云服务器
- PaaS平台服务 小程序开发平台 云上Hadoop平台
- SaaS服务 软件服务 云网盘、云数据库、流量高防



**阿里云初探**

我们是通过Vmware去搭建集群，然后这里正好接触一下阿里云的一些玩法入门

首先我们需要为集群准备好在云上的网络，在云上我们可以得到一个云上私有局域称为VPC，相当于物理的路由器，提供一个子网，允许我们将所需的资源放在网络内

安全组：云上虚拟流量防火墙，做一些流量出入的控制

然后去创建云服务器资源即可



**基于Vmware搭建集群环境**

这里我们克隆出node1、2、3三台机器，配置主机名、IP地址、SSH免密登录

以及JDK环境、关闭防火墙、以及SElinux、同时基于NTP做了时间同步

然后下面就进大数据学习



### 第二部分 数据存储

其实分布式存储的本质是文件太大单台服务器无法承担，于是将文件切片，分布存储在不同的服务器上，

注意这么做其实不仅解决了存储空间不够的问题，还有性能的横向扩展，三倍的网络传输效率、磁盘写入效率



分布式基础架构：

中心化 ： 一台服务器进行管理调度

去中心化：众多服务器基于特定规则进行同步协调

大多大数据框架都符合中心化模式，即主从模式



HDFS是Hadoop三大组件（HDFS、MapReduce、Yarn）之一

分三个角色



### 第三部分 数据计算

我们说大数据技术栈主要是围绕数据存储、计算、传输、资源调度这几个方面

而分布式计算是多台服务器协同工作共同完成一个计算任务

然后计算的模式有两种，分散-->汇总（MapReduce）、中心调度--->步骤执行（Spark、Flink）



MapReduce的本质是提供Map、Reduce接口，然后有对应的MapTask和ReduceTask分配到对应服务器执行



而计算就肯定需要有计算资源（CPU、内存、磁盘等）

我们需要对整个集群的资源进行统一管理，即交给YARN

我们的程序向YARN申请资源，然后YARN来分配容器给程序运行



**Yarn架构**

ResourceManager 整个集群的资源调度者

NodeManager 单个服务器的资源调度者，会预先占用资源构建一个容器，然后提供给程序使用

应用程序运行在容器内，无法突破容器的资源限制



然后Yarn还有两个辅助角色

- web代理服务器 默认作为RM资源管理器的一部分运行 也可独立运行 YARN在运行时也会提供一个WEB站点和HDFS一样，用户可以在浏览器查看信息
- 历史服务器 因为程序运行信息分布在各个容器内 统一收集日志到HDFS 提供web ui查看 



**部署**

Mapreduce是运行在YARN内的，不需要启动进程，未来我们的mr程序是直接跑在yarn内



### 第四部分 Hive

Hive本质是把sql转为Mapreduce跑，操作的是HDFS文件的数据，通过DBMS元数据管理将数据拉起来

所以重点看Hive的几种表（分区、分桶、内部外部）然后对应HDFS里文件是怎么组织起来的



创建sql语法

![image-20240202110648677](D:\工作文档\知识库\assets\image-20240202110648677.png)



**内部表&外部表**

被external修饰 的是外部表 指表数据可以在任何位置 通过LOCATION关键字指定 

外部表设计理念不是Hive内部管理 用于临时链接到外部数据上，删除仅删元数据



内部表，其数据存储位置由hive.metastore.warehouse.dir参数指定，默认/user/hive/warehouse

删除会删数据本身+元数据



默认Hive的字段分隔符是特殊字符 可以通过row format delimited fields terminated by在创建表时修改



外部表和数据是独立的，你可以先有表再有数据，然后把数据移动到表location的位置即可

或是先有数据，然后创建表location数据 

内部表、外部表可以相互转换



**数据导入导出**

使用load语句，如果数据来源本地，本地数据文件会保留

如果是来自HDFS，加载后文件不存在，本质是在HDFS上进行文件移动

而为什么要将数据导入呢？重要数据建议存入内部表进行管理





理解：其实分区分桶，都是通过改变表的存储模式，从而完成对表优化

**分区表**

本质思想是分治，按照每个月或每天把大的数据切分成一个个小的文件，

**每一个分区是一个文件夹！**

Hive也支持多分区，即多层级文件夹



**分桶表**

将表拆分到固定数量的不同文件进行存储

分区和分桶是可以同时进行的

对分桶表加载数据时，一旦有了分桶设置，比如分桶数量为3，那么表内文件或分区内数据文件的数量就限定为3

当数据插入时，需要一分为三进入三个桶文件内，划分是基于分桶列的值进行hash取模来决定

由于load data是不会触发MapReduce的，无计算过程只是移动数据，无法执行hash算法，所以不能用于分桶表插入

所以必须使用insert select语法 来触发mapreduce 进行hash取模计算



**分区分桶的优化点**

分区表：在指定分区列的前提下，减少被操作的数据量，提升性能，相当于是只用去对应的文件夹里找

分桶表：基于分桶列的特定操作，例如过滤、JOIN、分组

例如基于分桶列过滤某个值，你就只用去对应的桶里去把数据排除，即可，其他桶就不用遍历操作



双表join时，以前是一条数据去对应一个表的数据，现在就是对应桶的数据join



group by的时候，在桶内去找对应的即可



**sql**

有时候我们需要对表进行随机抽样，对于大表一个简单的select也会很慢

因此Hive提供快速抽样的语法，本质是用TABLESAMPLE函数





### 第五部分--案例

基于社交平台APP的用户数据，实现指标的统计分析并结合BI工具进行可视化展现，给公司的发展决策提供精确的数据支撑



数据源清洗ETL：

有些数据有些问题，例如某些字段为空，只有整体时间字段，需要拆分为天、小时，将经纬度拆分

最终得到一张新的Hive表



ETL是指抽取、转换、加载，即从A抽取数据，进行转换过滤、将结果加载到B



然后我们通过Hive的sql统计出数据后

通过BI（商业智能）软件，例如帆软的FineBI，做可视化，配置报表等等，感觉有点像ArtNova

BI主要是用数仓技术、数分技术实现商业价值



![image-20240202154323096](D:\工作文档\知识库\assets\image-20240202154323096.png)





### 附录--启动命令

**所有的命令都以Hadoop用户启动**

1、HDFS 集群启动

start-dfs.sh ： 但执行此脚本的机器起secondarynamenode ，然后拉取core-site.xml起namenode 然后读worker配置项 起datanode

查看hadoop文件系统

查看指定目录下内容: hadoop fs -ls <path>

查看文件内容 hadoop fs -cat <src>



命令执行后 集群的三个角色 namenode secondarynamenode datanode都会起来



2、Yarn启动

有了Yarn环境后我们就可以在里面跑MR程序

start-yarn.sh : 读取hostname来启动resourcemanager，然后读取workers起nodemanager

然后代理服务器（web站点）会随着resourcemanager一起启动

mapred --daemon start historyserver启动历史服务器 会将容器日志统一收集到HDFS然后展示（可以在web站点看）



3、Hive部署

Hive本质其实两个 元数据管理 和 mr的翻译

**注意这条命令在/export/server/hive路径下跑**

先到目录下 cd /export/server/hive

然后通过nohup bin/hive --service metastore >> logs/metastore.log 2>&1 & 来启动metastore服务

然后bin/hive启动命令行

Hive Server2服务启动： 可以提供Thrift端口给其他客户端连接 Hive内置beeline、或是navicat等

nohup bin/hive --service hiveserver2 >> logs/hiveserver2.log 2>&1 & 



这个启动完后 我们就可以在IDEA里连接了



### 









